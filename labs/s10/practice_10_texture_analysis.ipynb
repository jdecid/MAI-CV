{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Vision - Laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "## Practice 10: Texture Analysis\n",
    "==============================================================================================\n",
    "\n",
    "The exercises of this notebook will show how to perform image similarity search using:\n",
    "\n",
    "- Gaussian filters\n",
    "- Descriptors based on texture and color\n",
    "\n",
    "### Problem we want to solve\n",
    "\n",
    "- Given a query image **$x$** and a set of images **$X$** we would like to retreive the most similar to **$x$** images from  **$X$**. The function should return a feature vector obtained by averaging each filter response on the image.\n",
    "\n",
    "**Hint**:\n",
    "- Note that since at this moment we are focusing on the texture, we will not use the color of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import skimage\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import filters\n",
    "from skimage import io\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The images are resized to fasten the computation of features\n",
    "\n",
    "path = \"./images/texturesimages/rice/\"\n",
    "rice_images = [resize(skimage.io.imread(path + f), (64, 64)) for f in os.listdir(path)]\n",
    "\n",
    "path = \"./images/texturesimages/pasta/\"\n",
    "pasta_images = [resize(skimage.io.imread(path + f), (64, 64)) for f in os.listdir(path)]\n",
    "\n",
    "path = \"./images/texturesimages/pizza/\"\n",
    "\n",
    "pizza_images = [resize(skimage.io.imread(path + f), (64, 64)) for f in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## submission has to be done with the entire set of images\n",
    "## remove this cell for submission\n",
    "\n",
    "rice_images = rice_images[0:5]\n",
    "pasta_images = pasta_images[0:5]\n",
    "pizza_images = pizza_images[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(ncols=3, nrows=1, figsize=(8,8))\n",
    "\n",
    "ax[0].imshow(rice_images[0])\n",
    "ax[1].imshow(pasta_images[0])\n",
    "ax[2].imshow(pizza_images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rice_images), len(pasta_images), len(pizza_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter banks\n",
    "\n",
    "We can apply a collection of multiple filters that we call a filter bank. Note that if we apply $D$ filters our feature vectors will be $D$ dimensional.\n",
    "\n",
    "The following image shows a filter bank. In the filter bank we typically want filters to capture a combination of scales, orientations of different types of patterns. This particular filter bank is The Leung-Malik (LM) Filter Bank.\n",
    "\n",
    "<img src=\"./images_notebook/filter_bank.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leung-Malik (LM) Filter Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LM_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bank = LM_filters.makeLMfilters()\n",
    "filter_bank.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_filters = filter_bank.shape[-1]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=12, nrows=4, figsize=(15,3))\n",
    "\n",
    "k = 0\n",
    "for i in range(4):\n",
    "    for j in range(12):\n",
    "        ax[i,j].imshow(filter_bank[:,:,k], cmap = 'gray')\n",
    "        ax[i,j].axis(\"off\")\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Plot the convolved image by some of the filters\n",
    "\n",
    "\n",
    "Make a function `visualize_features(im,  filter_bank, n_filters=5)` that recieves the `filter_bank`, an image `im` and an integer `n_filters`. \n",
    "\n",
    "The function  must make a plot of two rows containing in the first row, in position $k$, the image convolved by filter $k$. In the second row, in position $k$, the image of the k'th filter. The result for `n_filter=5` should look like \n",
    "\n",
    "\n",
    "<img src=\"./images/filters.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = pasta_images[0]\n",
    "im = skimage.color.rgb2gray(pasta_images[0])\n",
    "plt.imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(im,  filter_bank, n_filters=5):\n",
    "    fig, ax = plt.subplots(ncols=n_filters, nrows=2, figsize=(15,6))\n",
    "    # complete this function\n",
    "    \n",
    "\n",
    "visualize_features(im, filter_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the 'visualize_features' function on images from the other two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 10.2 Constructing a feature vector for a given image\n",
    "\n",
    "\n",
    "Given $D$ filters from the filter bank and a single image `image`, make a function `features_from_filter_bank(image, filter_bank, n_filters)` that returns a feature vector of shape `n_filters`. The returned vector must contain at position $k$ the mean of the absolute value of the convolved image by filter $k$.\n",
    "\n",
    "$$\n",
    "\\text{feat}(x) = \\left( \\text{mean}( |r_1|), \\dots,\\text{mean}(|r_D|) \\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "im = skimage.color.rgb2gray(pasta_images[0])\n",
    "\n",
    "def features_from_filter_bank(image, filter_bank, n_filters):\n",
    "    ## Complete this function\n",
    "  \n",
    "    return features_for_im\n",
    "\n",
    "features_for_im = features_from_filter_bank(im, filter_bank, n_filters)\n",
    "print(features_for_im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Constructing the matrix of the feature vectors for all images\n",
    "\n",
    "Implement a function `get_class_Features(all_images, filter_bank)` that applies `features_from_filter_bank` to get a feature vector for each of the images in the union of the three datasets (forest, buildings, sunset). It must return a matrix containing at row $k$ feature vector for the input image $k$.\n",
    "\n",
    "\n",
    "Wall time: 7min 49s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = rice_images + pasta_images + pizza_images\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_class_features(all_images,  filter_bank):\n",
    "\n",
    "    n_images = len(all_images)\n",
    "    n_filters = filter_bank.shape[-1]\n",
    "    all_feature_vectors=np.zeros((n_images,filter_bank.shape[-1]))\n",
    "    # Complete\n",
    "    \n",
    "\n",
    "    return all_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_feature_vectors=get_class_features(all_images,  filter_bank)\n",
    "print(all_feature_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 Visualizing the features of an image\n",
    "\n",
    "Define a function `visualize_features` that given a feature index and an array containing all feature vectors, plots its values for the three datasets using different colors for each dataset (in total plots should contain 3 colors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(k, all_feature_vectors):\n",
    "    # complete\n",
    "    \n",
    "\n",
    "visualize_features(25, all_feature_vectors)    \n",
    "visualize_features(41, all_feature_vectors)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 Retrieving the most similar images\n",
    "\n",
    "Implement a function `retrieve_k_images_from_X(query, X, k)` where `query` is an image, `X` ins the array containing the features from all the images and `k` is an integer. The function should retrieve the `k` most similar images (according to the l2 norm) and the distances from the closest images to the query image. You can include the query image since it is in `X`.\n",
    "\n",
    "- Make a plot with the first column beeing the query image and the other k columns the closest images in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search\n",
    "\n",
    "Let us assume $f(x) \\in \\mathbb{R}^D$ represents a set of features for $x$. Given a query image $x$ and another image $x^m$ from the database, we can compute the distance between images as\n",
    "$$\n",
    "\\text{distance}\\left( f(x) , \\, f(x^m) \\right) = \\| \\text{feat}(x)  - \\text{feat}(x^m)  \\|_2 =  \\sqrt{ \\sum_{d=1}^\\text{D} \\left( f(x)_d - f(x^m)_d  \\right)^2 }\n",
    "$$\n",
    "\n",
    "then we can find the closest image $x^{m^*}$ from the database to $x$ as $m^* =  \\text{argmin}_{m} \\{ \\| \\text{feat}(x)  - \\text{feat}(x^m)  \\|_2 \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_feature_vectors)\n",
    "ind_1 = 6\n",
    "ind_2 = 12\n",
    "ind_3 = 15\n",
    "\n",
    "query_1 = X[ind_1, :]\n",
    "query_2 = X[ind_2,:]\n",
    "query_3 = X[ind_3,:]\n",
    "\n",
    "# Display the query images\n",
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(15,3))\n",
    "ax[0].imshow(all_images[ind_1]) \n",
    "ax[1].imshow(all_images[ind_2])\n",
    "ax[2].imshow(all_images[ind_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_k_images_from_X(query, X, k):\n",
    "    #Complete\n",
    "    \n",
    "    return closest_images, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6 Compute the accuracy of the algorithm: given a query image. \n",
    "\n",
    "Make a function \n",
    "\n",
    "```\n",
    "accuracy(X, class_labels, k=5, query=x, class_query=y)\n",
    "```\n",
    "\n",
    "That takes as input a the dataset `X`, the `class_labels` for the images, the number of images to retrieve `k`, a query image `x` and the class of the query image `y`. Returns as output the number of retrieved images that belong to class `y` divided by the total of images retrieved `k` (this is the accuracy).\n",
    "\n",
    "**Hint**: be careful to exclude the query image from the retrieved images.\n",
    "\n",
    "- Compute the accuracy with k=4 with the previous images. Does the accuracy match the images retrieved from the previous exercise?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.concatenate((np.zeros(30), np.ones(30),  2*np.ones(30))).reshape(90,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, class_labels, k, query, class_query):\n",
    "    # Complete\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7 Image retrieval based on texture and color. \n",
    "\n",
    "Make a function ` lm_features_rgb(image, filter_bank)`  that returns the features from the filter bank concatenated per color. If the previous feature vectors had 49 components now they will have 49*3 components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_features_rgb(image, filter_bank):\n",
    "\n",
    "    n_filters = len(filter_bank)\n",
    "    im_conv = np.array(image[:,:,0])\n",
    "    features_for_im = np.zeros(3*n_filters)\n",
    "    # Complete        \n",
    "        \n",
    "    return features_for_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "lm_rgb_features = lm_features_rgb(all_images[0], filter_bank)\n",
    "print(lm_rgb_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.8 Apply the function to all the images in the dataset\n",
    "\n",
    "Using ` lm_features_rgb(image, filter_bank)` build the features of all the datapoints in and save them in `X_lm_rgb`.\n",
    "\n",
    "**Hint**\n",
    "- You can parallelize the feature building process using `joblib.Parallel`. This will make the computation much faster if you have a processor with more than two threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.9 Compute the accuracy of the method using lm rgb features\n",
    "\n",
    "Use the function implemented in 10.6 to compute the accuracy of the retrieved images using the features that contain color information. Make a plot of the 4 closest images to the query images in the `lm_rgb` space.\n",
    "\n",
    "- Is the accuracy higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute (X_lm_rgb) and cast it as array\n",
    "X_lm_rgb = np.array(X_lm_rgb)\n",
    "print(X_lm_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery\n",
    "\n",
    "### Compressed File\n",
    "\n",
    "- P10_Student1_Student2.zip that includes:\n",
    "- The notebook P10_Student1_Student2.ipynb completed with the solutions to the exercises and their corresponding comments.\n",
    "- The images used to run the notebook.\n",
    "\n",
    "**Deadline (Campus Virtual): December 16, 11.00 p.m.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
