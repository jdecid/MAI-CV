{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5 Computational Vision\n",
    "\n",
    "**Important:** Read the file `README.md` before start coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "    \n",
    "**Delivery**\n",
    "<ol>\n",
    "\n",
    "Requirements to fulfill:\n",
    "<ul>\n",
    "    <li>  Answer the questions introduced in the exercises.\n",
    "    <li>  The implemented code should be,<br>\n",
    "        - free of errors (Run All before delivery and check for possible errors)<br>\n",
    "        - optimized ( e.g. do not use 'for' instruction when indexing numpy arrays)<br>\n",
    "        - readable  ( e.g. avoiding the implementation of more than 2 loops within a line)<br>\n",
    "        - commented and with descriptions      \n",
    "    <li> The deliverable must be a file named **P4_Student1_Student2.zip** that includes:\n",
    "    <ul>\n",
    "        <li> The notebook P4_Student1_Student2.ipynb completed with the solutions to the exercises and their corresponding comments.\n",
    "         <li> All the images used in this notebook.\n",
    "    </ul>\n",
    "\n",
    "</ul>\n",
    "\n",
    " **Deadline (Campus Virtual): November 11th, 23:00 h** \n",
    "\n",
    "\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection\n",
    "\n",
    "The main topics of this notebook:\n",
    "\n",
    "- Integral images and a classical use for fast haar-like feature computation.\n",
    "- Viola & Jones face detection method applied in a video.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import time\n",
    "import timeit\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "1) Build a function `compute_integral_image` that computes the integral image of an input (2D) array.\n",
    "\n",
    "\n",
    "In an integral image each pixel is the sum of all pixels in the original image that are 'left and above' the pixel. See the following example:\n",
    "\n",
    "```python\n",
    "Original    Integral\n",
    "+--------   +------------\n",
    "| 1 2 3 .   | 0  0  0  0 .\n",
    "| 4 5 6 .   | 0  1  3  6 .\n",
    "| . . . .   | 0  5 12 21 .\n",
    "            | . . . . . .\n",
    "\n",
    "```\n",
    "The integral image must have an additional row and column full of zeros (first row and first column).\n",
    "\n",
    "```python\n",
    " def compute_integral_image(img_arr):\n",
    "    row_sum = np.zeros(img_arr.shape)\n",
    "    integral_image_arr = np.zeros((img_arr.shape[0] + 1, img_arr.shape[1] + 1))\n",
    "    # Add code here\n",
    "    \n",
    "    return integral_image_arr\n",
    "```\n",
    "\n",
    "\n",
    "2) Make sure that the values of the integral image are correct.\n",
    "\n",
    "\n",
    "3) Plot the output of the integral image for the following array:\n",
    "\n",
    "```\n",
    "img_array = np.array([[1,2,2,2,1],[1,2,2,2,1],[1,2,2,2,1],[1,2,2,2,1]])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_array = np.array([\n",
    "    [1, 2, 2, 2, 1],\n",
    "    [1, 2, 2, 2, 1],\n",
    "    [1, 2, 2, 2, 1],\n",
    "    [1, 2, 2, 2, 1]\n",
    "])\n",
    "\n",
    "plt.imshow(img_array, cmap='gray', vmin=0, vmax=5)\n",
    "plt.title('Array image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_integral_image(img_arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the integral image based on this instance's original image data.\n",
    "    :param img_arr: Image source data\n",
    "    :return Integral image of \"img_arr\"\n",
    "    \"\"\"\n",
    "    # an index of -1 refers to the last row/column\n",
    "    # since row_sum is calculated starting from (0,0),\n",
    "    # rowSum(x, -1) == 0 holds for all x\n",
    "    row_sum = np.zeros(img_arr.shape)\n",
    "    # we need an additional column and row\n",
    "    integral_image_arr = np.zeros((img_arr.shape[0] + 1, img_arr.shape[1] + 1))\n",
    "    \n",
    "    # Add code here\n",
    "    integral_image_arr[1:, 1:] = np.cumsum(np.cumsum(img_arr, axis=0), axis=1)\n",
    "\n",
    "    return integral_image_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD3CAYAAAA+C7CYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAKuElEQVR4nO3be4xcVR3A8e+PLlAehQoasYKtJPIMqFl5mEiCBDFgjA0IilhQgSpBIwkokSiUiCBGE1AUjDE2CIoxWgUMEgiWR4CoGDVGREHAQinyflYFPP5xzsrtdmYf9Led7vb7SSaduffOzDl3Z75z5+42SilI0rraZNADkDQzGBNJKYyJpBTGRFIKYyIphTGRlMKYrEcRsSQiLuuz7oCIuGt9jylTVN+LiCci4teDHs9ERMQlEfGFQY9jJpj2MYmI+yLi4AluuzwiTpjqMb0SpZSbSym7Dnoc6+gdwLuAHUsp+/bbKCIOjIgSEaevv6H1Vkr5RCnli4Mex0ww7WOyoYiIoUGPYQMwH7ivlPLcONsdBzwOHDvWRr32qft5A1ZKmdYX4D7g4Hb9I8AtwFeBJ4B7gUPbui8BLwH/Ap4FLmrLdwOuo7647wKO6jz29sBVwNPAb4BzgFs66wtwMvA34N627EJgRbvPHcABne2XAJf1mceBwAOj5vUZ4I/Ac8B3gdcC1wDPANcDr+ps/2NgFfAUcBOw5yTm0Xcf9BjnPODKtu3dwIlt+fFt377U9u/Zfe6/VRv/B4H/AG/rrFvQ9unxwD/aPNZaNtZ8gX2Ah4FZncc9HPhDn/EsBc7p/gyAzwL/BB4CFgKHAX9tcz6jc999gduAJ9u2FwGbddYf0vbnU8C3gBuBEzrrPwbcSX2tXgvMH/T7aZ3ei4MewDpPYO2YvACcCMwCTgJWAtHWLx/1w9yK+sb/KDAEvBV4FNijrb+iXbYE9mjbjo7JdcB2wBZt2Yepb94h4NT2gp/d1i1hcjG5nRqQ17cX9+/aGGcDNwBnjXphzgE2By4Aft9Z13ce4+2DHuO8qb0xZgNvAR4BDurs/1t63a9z/0XtjTeLGrhvdNYtaPv00jauLXotm8B8/0z7EGm3lwGn9hnPUtaMyYvAmcCm1NfRI8AP2nPtCawG3ti2Hwb2b/ttATUMp7R1r6bG+/C2/tPU1+YJbf37qDHeva3/PHDroN9P6/ReHPQA1nkCa8fk7s66LdsLcYd2ezlrxuQDwM2jHu/bwFntxf4CsGtnXa8jk4PGGd8TwJvb9SVMLibHdG7/BLi4c/tTwM/6PNbcNrZtx5vHWPugx+PuRD3ymNNZdh6wtLP/x4vJ9cAF7frR7c26abu9oI175872ay0ba77t9unA5e36dsDzwOv63Hcpa8ZkNe2ohhqQAuzX2f4OYGGfxzoFWNauHwvc1lkX1GiPxOQa4PjO+k3aOOcP+j31Si8z8ZzJqpErpZTn29Wt+2w7H9gvIp4cuQDHADsAr6F+YqzobL+ix2OssSwiTouIOyPiqfZ421I/pV6JhzvXV/e4vXV7zlkR8eWIuCcinqaGiPa8481jrH0w2jzg8VLKM51l91OPnMYVETsB7wQub4t+Tj3Cec+oTcfcz+PMF+Ay4L0RsRVwFDWWD01kjMBjpZSX2vXV7d9++32XiLg6Ila1cZzbGcO87phLLcYDnceZD1zY2eePU4MzoX25IZqJMRnL6P8ivQK4sZQyt3PZupRyEvUT80Vgx872O431mBFxAPX79lHU8xlzqd+XI3MSPXyIeth8MDVeC0aGxPjzGGsfjLYS2C4i5nSWvQF4cILjXER9zV0VEauAv1Njctyo7Xr9V/busrHmSynlQeq5jMPbc35/guObrIuBvwBvKqVsA5zByz/rh+js84gI1vwZrAA+Pmq/b1FKuXWKxjrlNraYPAzs3Ll9NbBLRCyKiE3bZZ+I2L19Ov0UWBIRW0bEbozz2wfqYfGL1DfwUEScCWwzBfPo9bz/Bh6jfrU7d2TFBObRdx+MfpJSygrgVuC8iJgdEXtTT4z2/NuZHo4Dzqaeaxm5HAEcFhHbZ8y341Jq2Peizn8qzKGeF3m27ddugH8B7BURC9tvoE5mzaO9S4DPRcSeABGxbUQcOUXjXC82tphcCLy//VHV19vh+iHU3yyspH5FOp96Ug/gk9RPvlXUT7cfUl/E/VwL/JJ65v9+6m83eh2yZ7u0Pd+D1JOPt49a33ceE9gHox1NPRJYST2xeVYp5frxBhgR+1MP7b9ZSlnVuVxJPRF59EQny/jzpY1tPvUcxvM91mc4jXqU9AzwHeBHIytKKY8CRwJfoUZvD+C3vLzfl1H38xXtK9KfgEOnaJzrxchvOTQBEXE+9WTu6MPyaWWmzGM8EXEP9avEuLFbD2PZhHrO5JhSyq8GPZ6psLEdmUxKROwWEXu3PxPfl3pIv2zQ45qsmTKPyYiII6jnWW4Y4BjeHRFzI2JzXj6f0usoakbwrwnHNof6lWAe9XzL16i/gZhuZso8JiQillO/Viwqpfx3gEN5O/VvVDajfh1bWEpZPfZdpi+/5khK4dccSSnG/JoTER62SPq/Ukrfv5nyyERSCmMiKYUxkZTCmEhKYUwkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUwphISmFMJKUwJpJSGBNJKYyJpBTGRFIKYyIphTGRlMKYSEphTCSlMCaSUhgTSSmMiaQUxkRSCmMiKYUxkZTCmEhKYUwkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUwphISmFMJKUwJpJSGBNJKYyJpBTGRFIKYyIphTGRlGJo0APIMjw8POghTMrixYsHPYQJm05j1eB4ZCIphTGRlMKYSEphTCSlMCaSUhgTSSmMiaQUxkRSCmMiKYUxkZTCmEhKYUwkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUwphISmFMJKUwJpJSGBNJKYyJpBTGRFIKYyIphTGRlMKYSEphTCSlMCaSUhgTSSmMiaQUxkRSCmMiKYUxkZTCmEhKYUwkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUYmjQA8gyPDw86CFMyuLFiwc9BCmVRyaSUhgTSSmMiaQUxkRSCmMiKYUxkZTCmEhKYUwkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUwphISmFMJKUwJpJSGBNJKYyJpBTGRFIKYyIphTGRlMKYSEphTCSlMCaSUhgTSSmMiaQUxkRSCmMiKYUxkZTCmEhKYUwkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUwphISmFMJKUwJpJSGBNJKYyJpBRDgx5AluHh4UEPQdqoeWQiKYUxkZTCmEhKYUwkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUwphISmFMJKUwJpJSGBNJKYyJpBTGRFIKYyIphTGRlMKYSEphTCSlMCaSUhgTSSmMiaQUxkRSCmMiKYUxkZTCmEhKYUwkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUwphISmFMJKUwJpJSGBNJKYyJpBTGRFIKYyIphTGRlGJo0APIMjw8POghSBs1j0wkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUwphISmFMJKUwJpJSGBNJKYyJpBTGRFIKYyIphTGRlMKYSEphTCSlMCaSUhgTSSmMiaQUxkRSCmMiKYUxkZTCmEhKYUwkpTAmklIYE0kpjImkFMZEUgpjIimFMZGUwphISmFMJKUwJpJSGBNJKYyJpBTGRFIKYyIphTGRlMKYSEphTCSlMCaSUhgTSSmilDLoMUiaATwykZTCmEhKYUwkpTAmklIYE0kpjImkFP8D9QS9kHrT5m4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ii_img_array = compute_integral_image(img_array)\n",
    "\n",
    "plt.imshow(ii_img_array, cmap='gray', vmin=0, vmax= 5)\n",
    "plt.title('Integral image of Array image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "1) Create a function `sum_region` to compute the  sum of the pixel intensities within a  rectangle using the integral image. \n",
    "\n",
    "The rectangle will be defined using the top left (x, y) and bottom right (x, y) coordinates.\n",
    "\n",
    "Make the function with the following header:\n",
    "```\n",
    "def sum_region(integral_img_arr, top_left, bottom_right):\n",
    "```\n",
    "\n",
    "2) You can make the following tests:\n",
    " \n",
    " - `sum(img_array) == ii_img_array[-1,-1]`\n",
    " - `img_array[0,:].sum() == ii_img_array[1,-1]`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(img_array.sum() == ii_img_array[-1, -1])\n",
    "assert(img_array[0, :].sum() == ii_img_array[1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_region(integral_img_arr, tl, br):\n",
    "    tr = (tl[0], br[1])\n",
    "    bl = (br[0], tl[1])\n",
    "    \n",
    "    return integral_img_arr[tl] + integral_img_arr[br] - (integral_img_arr[tr] + integral_img_arr[bl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result you should get (12)\n",
    "sum_region(ii_img_array, tl=(1, 1), br=(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result you should get (32)\n",
    "sum_region(ii_img_array, tl=(0, 0), br=(-1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise 3:**\n",
    "\n",
    "Compute the integral image for a set of images.\n",
    "    \n",
    "To do so build a function `load_integral_images` to read all the images inside a given folder and compute the integral image of every image:\n",
    "\n",
    "```python\n",
    "def load_integral_images(path):\n",
    "    images = []\n",
    "    for _file in os.listdir(path):\n",
    "       #### Complte here:\n",
    "       #### Read image\n",
    "       #### Remember to scale the image (with the max pixel intensity value)\n",
    "     \n",
    "    return ii_images\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_training_path = 'trainingdata/faces'\n",
    "neg_training_path = 'trainingdata/nonfaces'\n",
    "pos_testing_path =  'trainingdata/faces/test'\n",
    "neg_testing_path =  'trainingdata/nonfaces/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_integral_images(path):\n",
    "    \"\"\"Read each file in the folder, calculate its integral image and normalize the image.\"\"\"\n",
    "    ii_images = []\n",
    "    \n",
    "    for file_path in glob(f'{path}/*.png'):\n",
    "        img = io.imread(file_path)\n",
    "        \n",
    "        i_img = compute_integral_image(img)\n",
    "        \n",
    "        ii_images.append(i_img / i_img.max())\n",
    "    \n",
    "    return ii_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepdecidrodriguez/Envs/CV-FBp3OsoO/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "ii_pos_training = load_integral_images(pos_training_path)\n",
    "ii_pos_testing = load_integral_images(pos_testing_path)\n",
    "ii_neg_training = load_integral_images(neg_training_path)\n",
    "ii_neg_testing = load_integral_images(neg_testing_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise 4:** \n",
    "\n",
    "Compute the Haar features of an image\n",
    "\n",
    "We provide you with `HaarLikeFeature` class that has build in a `get_score` function and a `get_vote` function.\n",
    "\n",
    "Your job is to complete the code of the method `_create_features` in the class `HaarLikeFeature`:\n",
    "\n",
    "```python\n",
    "def _create_features(img_height, img_width, min_feature_width, max_feature_width, min_feature_height, max_feature_height):\n",
    "    print('Creating Haar-like features..')\n",
    "    t0 = time.time()\n",
    "    features = []\n",
    "    for feature in FeatureTypes:\n",
    "        # FeatureTypes are just tuples\n",
    "        feature_start_width = max(min_feature_width, feature[0])\n",
    "        for feature_width in range(feature_start_width, max_feature_width, feature[0]):\n",
    "            feature_start_height = max(min_feature_height, feature[1])\n",
    "            for feature_height in range(feature_start_height, max_feature_height, feature[1]):\n",
    "                # Loop over possible x values and y values \n",
    "                # - For each (x,y) create the HarrLikeFeature objects.\n",
    "                # - append the HaarlikeFeatures in the features list.\n",
    "                # Notice that Haarlike features contain polarity, append features for polarity 1 and -1\n",
    "                # The threshold can be set to 0 for all of them.\n",
    "                \n",
    "                \n",
    "    print('\\t' + str(len(features)) + ' features created.')\n",
    "    print('\\tTime needed for calculating Harr-like features:', time.time()-t0)\n",
    "    return features\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enum(**enums):\n",
    "    return type('Enum', (), enums)\n",
    "\n",
    "FeatureType = enum(TWO_VERTICAL=(1, 2), TWO_HORIZONTAL=(2, 1), THREE_HORIZONTAL=(3, 1), THREE_VERTICAL=(1, 3), FOUR=(2, 2))\n",
    "FeatureTypes = [FeatureType.TWO_VERTICAL, FeatureType.TWO_HORIZONTAL, FeatureType.THREE_VERTICAL, FeatureType.THREE_HORIZONTAL, FeatureType.FOUR]\n",
    "\n",
    "class HaarLikeFeature(object):\n",
    "    \"\"\"\n",
    "    Class representing a haar-like feature.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_type, position, width, height, threshold, polarity):\n",
    "        \"\"\"\n",
    "        Creates a new haar-like feature.\n",
    "        :param feature_type: Type of new feature, see FeatureType enum\n",
    "        :type feature_type: HaarLikeFeature.FeatureTypes\n",
    "        :param position: Top left corner where the feature begins (x, y)\n",
    "        :type position: (int, int)\n",
    "        :param width: Width of the feature\n",
    "        :type width: int\n",
    "        :param height: Height of the feature\n",
    "        :type height: int\n",
    "        :param threshold: Feature threshold\n",
    "        :type threshold: float\n",
    "        :param polarity: polarity of the feature -1 or 1\n",
    "        :type polarity: int\n",
    "        \"\"\"\n",
    "        self.type = feature_type\n",
    "        self.top_left = position\n",
    "        self.bottom_right = (position[0] + width, position[1] + height)\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "        self.weight = 1\n",
    "    \n",
    "    def get_score(self, int_img):\n",
    "        \"\"\"\n",
    "        Get score for given integral image array.\n",
    "        :param int_img: Integral image array\n",
    "        :type int_img: numpy.ndarray\n",
    "        \n",
    "        :return: Score for given feature\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        if self.type == FeatureType.TWO_VERTICAL:\n",
    "            first = sum_region(int_img, self.top_left, (self.top_left[0] + self.width, int(self.top_left[1] + self.height / 2)))\n",
    "            second = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + self.height / 2)), self.bottom_right)\n",
    "            score = first - second\n",
    "        elif self.type == FeatureType.TWO_HORIZONTAL:\n",
    "            first = sum_region(int_img, self.top_left, (int(self.top_left[0] + self.width / 2), self.top_left[1] + self.height))\n",
    "            second = sum_region(int_img, (int(self.top_left[0] + self.width / 2), self.top_left[1]), self.bottom_right)\n",
    "            score = first - second\n",
    "        elif self.type == FeatureType.THREE_HORIZONTAL:\n",
    "            first = sum_region(int_img, self.top_left, (int(self.top_left[0] + self.width / 3), self.top_left[1] + self.height))\n",
    "            second = sum_region(int_img, (int(self.top_left[0] + self.width / 3), self.top_left[1]), (int(self.top_left[0] + 2 * self.width / 3), self.top_left[1] + self.height))\n",
    "            third = sum_region(int_img, (int(self.top_left[0] + 2 * self.width / 3), self.top_left[1]), self.bottom_right)\n",
    "            score = first - second + third\n",
    "        elif self.type == FeatureType.THREE_VERTICAL:\n",
    "            first = sum_region(int_img, self.top_left, (self.bottom_right[0], int(self.top_left[1] + self.height / 3)))\n",
    "            second = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + self.height / 3)), (self.bottom_right[0], int(self.top_left[1] + 2 * self.height / 3)))\n",
    "            third = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + 2 * self.height / 3)), self.bottom_right)\n",
    "            score = first - second + third\n",
    "        elif self.type == FeatureType.FOUR:\n",
    "            # top left area\n",
    "            first = sum_region(int_img, self.top_left, (int(self.top_left[0] + self.width / 2), int(self.top_left[1] + self.height / 2)))\n",
    "            # top right area\n",
    "            second = sum_region(int_img, (int(self.top_left[0] + self.width / 2), self.top_left[1]), (self.bottom_right[0], int(self.top_left[1] + self.height / 2)))\n",
    "            # bottom left area\n",
    "            third = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + self.height / 2)), (int(self.top_left[0] + self.width / 2), self.bottom_right[1]))\n",
    "            # bottom right area\n",
    "            fourth = sum_region(int_img, (int(self.top_left[0] + self.width / 2), int(self.top_left[1] + self.height / 2)), self.bottom_right)\n",
    "            score = first - second - third + fourth\n",
    "        return score\n",
    "    \n",
    "    def get_vote(self, int_img):\n",
    "        \"\"\"\n",
    "        Get vote of this feature for given integral image.\n",
    "        :param int_img: Integral image array\n",
    "        :type int_img: numpy.ndarray\n",
    "        \n",
    "        :return: 1 iff this feature votes positively, otherwise -1\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        score = self.get_score(int_img)\n",
    "        return self.weight * (1 if score < self.polarity * self.threshold else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn(positive_iis, negative_iis, num_classifiers=-1, min_feature_width=1, max_feature_width=-1, min_feature_height=1, max_feature_height=-1):\n",
    "    \"\"\"\n",
    "    Selects a set of classifiers. Iteratively takes the best classifiers based\n",
    "    on a weighted error.\n",
    "    :param positive_iis: List of positive integral image examples\n",
    "    :type positive_iis: list[numpy.ndarray]\n",
    "    :param negative_iis: List of negative integral image examples\n",
    "    :type negative_iis: list[numpy.ndarray]\n",
    "    :param num_classifiers: Number of classifiers to select, -1 will use all\n",
    "    classifiers\n",
    "    :type num_classifiers: int\n",
    "    \n",
    "    :return: List of selected features\n",
    "    :rtype: list[HaarLikeFeature.HaarLikeFeature]\n",
    "    \"\"\"\n",
    "    num_pos = len(positive_iis)\n",
    "    num_neg = len(negative_iis)\n",
    "    num_imgs = num_pos + num_neg\n",
    "    img_height, img_width = positive_iis[0].shape\n",
    "\n",
    "    # Maximum feature width and height default to image width and height\n",
    "    max_feature_height = img_height if max_feature_height == -1 else max_feature_height\n",
    "    max_feature_width = img_width if max_feature_width == -1 else max_feature_width\n",
    "\n",
    "    # Create initial weights and labels\n",
    "    pos_weights = np.ones(num_pos) * 1. / (2 * num_pos)\n",
    "    neg_weights = np.ones(num_neg) * 1. / (2 * num_neg)\n",
    "    weights = np.hstack((pos_weights, neg_weights))\n",
    "    labels = np.hstack((np.ones(num_pos), np.ones(num_neg) * -1)) \n",
    "\n",
    "    images = positive_iis + negative_iis\n",
    "\n",
    "    # Create features for all sizes and locations\n",
    "    features = _create_features(img_height, img_width, min_feature_width, max_feature_width, min_feature_height, max_feature_height)\n",
    "    num_features = len(features)\n",
    "    feature_indexes = list(range(num_features))\n",
    "\n",
    "    num_classifiers = num_features if num_classifiers == -1 else num_classifiers\n",
    "\n",
    "    print('Calculating scores for images..')\n",
    "    t0 = time.time()\n",
    "    votes = np.zeros((num_imgs, num_features))\n",
    "    # Use as many workers as there are CPUs\n",
    "    pool = Pool(processes=8)\n",
    "    for i in range(num_imgs):\n",
    "        votes[i, :] = np.array(list(pool.map(partial(_get_feature_vote, image=images[i]), features)))\n",
    "\n",
    "    \n",
    "    print('\\tTime needed for calculating scores:', time.time()-t0)\n",
    "    \n",
    "    # select classifiers\n",
    "    classifiers = []\n",
    "\n",
    "    t0 = time.time()\n",
    "    print('Selecting classifiers..')\n",
    "    for _ in range(num_classifiers):\n",
    "\n",
    "        classification_errors = np.zeros(len(feature_indexes))\n",
    "\n",
    "        # normalize weights\n",
    "        weights *= 1. / np.sum(weights)\n",
    "\n",
    "        # select best classifier based on the weighted error\n",
    "        for f in range(len(feature_indexes)):\n",
    "            f_idx = feature_indexes[f]\n",
    "            # classifier error is the sum of image weights where the classifier\n",
    "            # is right\n",
    "            error = sum(map(lambda img_idx: weights[img_idx] if labels[img_idx] != votes[img_idx, f_idx] else 0, range(num_imgs)))\n",
    "            classification_errors[f] = error\n",
    "\n",
    "        # get best feature, i.e. with smallest error\n",
    "        min_error_idx = np.argmin(classification_errors)\n",
    "        best_error = classification_errors[min_error_idx]\n",
    "        best_feature_idx = feature_indexes[min_error_idx]\n",
    "\n",
    "        # set feature weight\n",
    "        best_feature = features[best_feature_idx]\n",
    "        feature_weight = 0.5 * np.log((1 - best_error) / best_error)\n",
    "        best_feature.weight = feature_weight\n",
    "\n",
    "        classifiers.append(best_feature)\n",
    "\n",
    "        # update image weights\n",
    "        weights = np.array(list(map(lambda img_idx: weights[img_idx] * np.sqrt((1-best_error)/best_error) if labels[img_idx] != votes[img_idx, best_feature_idx] else weights[img_idx] * np.sqrt(best_error/(1-best_error)), range(num_imgs))))\n",
    "\n",
    "        # remove feature (a feature can't be selected twice)\n",
    "        feature_indexes.remove(best_feature_idx)\n",
    "\n",
    "    print('\\tTime needed for Selecting Classifiers:', time.time()-t0,'\\n')\n",
    "\n",
    "\n",
    "    return classifiers\n",
    "\n",
    "def _get_feature_vote(feature, image):\n",
    "    return feature.get_vote(image)\n",
    "\n",
    "def _create_features(img_height, img_width, min_feature_width, max_feature_width, min_feature_height, max_feature_height):\n",
    "    print('Creating Haar-like features..')\n",
    "    t0 = time.time()\n",
    "    features = []\n",
    "    for feature in FeatureTypes:\n",
    "        # FeatureTypes are just tuples\n",
    "        feature_start_width = max(min_feature_width, feature[0])\n",
    "        for feature_width in range(feature_start_width, max_feature_width, feature[0]):\n",
    "            feature_start_height = max(min_feature_height, feature[1])\n",
    "            for feature_height in range(feature_start_height, max_feature_height, feature[1]):\n",
    "                f = HaarLikeFeature(feature_type=feature,\n",
    "                                    position=(feature_start_width, feature_start_height),\n",
    "                                    width=feature_width,\n",
    "                                    height=feature_height,\n",
    "                                    polarity=0, threshold=0)\n",
    "                features.append(f)\n",
    "            \n",
    "    print('\\t' + str(len(features)) + ' features created.')\n",
    "    print('\\tTime needed for calculating Harr-like features:', time.time()-t0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** Use the learn method  to learn a list of two classifiers with the train data\n",
    "\n",
    "With the `learn` function you can build a list of classifiers that detect whether an image contains a face or not.\n",
    "\n",
    "Use the following hyperparameters of the features and `num_classifiers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classifiers = 2\n",
    "min_feature_height = 8\n",
    "max_feature_height = 10\n",
    "min_feature_width = 8\n",
    "max_feature_width = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Haar-like features..\n",
      "\t9 features created.\n",
      "\tTime needed for calculating Harr-like features: 0.00020503997802734375\n",
      "Calculating scores for images..\n",
      "\tTime needed for calculating scores: 14.614855766296387\n",
      "Selecting classifiers..\n",
      "\tTime needed for Selecting Classifiers: 0.3457968235015869 \n",
      "\n",
      "CPU times: user 9.82 s, sys: 1.76 s, total: 11.6 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "classifiers = learn(ii_pos_training,\n",
    "                    ii_neg_training,\n",
    "                    num_classifiers=num_classifiers,\n",
    "                    min_feature_height=min_feature_height,\n",
    "                    max_feature_height=max_feature_height,\n",
    "                    min_feature_width=min_feature_width,\n",
    "                    max_feature_width=max_feature_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** Make a function for voting with different classifiers\n",
    "\n",
    "Build two functions `ensemble_vote` and `ensemble_vote_all`.\n",
    "\n",
    "- `ensemble_vote(int_img, classifiers)` has to return a 1 if the majority of the votes of the classifiers is positive and a zero otherwise\n",
    "\n",
    "- `ensemble_vote_all(int_imgs, classifiers)` has to loop over the list `int_imgs` and compute the `ensemble_vote` for each image in the list. It has to return a list containing all the votes for all the images in  `int_imgs`.\n",
    "\n",
    "Use the functions to compute the train and test acurracies for faces and non faces.\n",
    "\n",
    "Print the results in the following format:\n",
    "```\n",
    "train results:\n",
    "Correctly identified Faces: 2129/2429  (87.64923836969946%)\n",
    "Correctly identified non-Faces: 4276/8548  (50.02339728591484%)\n",
    "\n",
    "test results:\n",
    "Correctly identified Faces: 300/472  (63.559322033898304%)\n",
    "Correctly identified non-Faces: 74/128  (57.8125%)\n",
    "```\n",
    "\n",
    "It is not required to get this exact results but print the information in this format. It facilitates understanding the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_vote(int_img, classifiers):\n",
    "    balance = 0\n",
    "    for c in classifiers:\n",
    "        vote = c.get_vote(int_img)\n",
    "        balance += 1 if vote >= 0 else -1\n",
    "    return 1 if vote >= 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_vote_all(int_imgs, classifiers):\n",
    "    votes = []\n",
    "    for img in int_imgs:\n",
    "        votes.append(ensemble_vote(img, classifiers))\n",
    "    return votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results:\n",
      "Correctly identified Faces: 7/2429 (0.2882%)\n",
      "Correctly identified non-Faces: 57/8548 (0.6668%)\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 0/472 (0.0000%)\n",
      "Correctly identified non-Faces: 0/128 (0.0000%)\n"
     ]
    }
   ],
   "source": [
    "def print_results():\n",
    "    print('train results:')\n",
    "\n",
    "    pos_training_results = ensemble_vote_all(ii_pos_training, classifiers)\n",
    "    percent = 100 * sum(pos_training_results) / len(ii_pos_training)\n",
    "    print(f'Correctly identified Faces: {sum(pos_training_results)}/{len(ii_pos_training)} ({percent:.4f}%)')\n",
    "\n",
    "    neg_training_results = ensemble_vote_all(ii_neg_training, classifiers)\n",
    "    percent = 100 * sum(neg_training_results) / len(ii_neg_training)\n",
    "    print(f'Correctly identified non-Faces: {sum(neg_training_results)}/{len(ii_neg_training)} ({percent:.4f}%)')\n",
    "\n",
    "    print('\\ntest results:')\n",
    "\n",
    "    pos_testing_results = ensemble_vote_all(ii_pos_testing, classifiers)\n",
    "    percent = 100 * sum(pos_testing_results) / len(ii_pos_testing)\n",
    "    print(f'Correctly identified Faces: {sum(pos_testing_results)}/{len(ii_pos_testing)} ({percent:.4f}%)')\n",
    "\n",
    "    neg_testing_results = ensemble_vote_all(ii_neg_testing, classifiers)\n",
    "    percent = 100 * sum(neg_testing_results) / len(ii_neg_testing)\n",
    "    print(f'Correctly identified non-Faces: {sum(neg_testing_results)}/{len(ii_neg_testing)} ({percent:.4f}%)')\n",
    "    \n",
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** Make another test with 20 classifiers instead of 2.\n",
    "\n",
    "Inspect the classification results if you use adaboost with 20 classifiers. Use the same hyperameters for the features.\n",
    "Print the results as in the previous exercise.\n",
    "\n",
    "- Discuss if the classification results improved in the train data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classifiers = 20\n",
    "min_feature_height = 8\n",
    "max_feature_height = 10\n",
    "min_feature_width = 8\n",
    "max_feature_width = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Haar-like features..\n",
      "\t9 features created.\n",
      "\tTime needed for calculating Harr-like features: 0.0001277923583984375\n",
      "Calculating scores for images..\n",
      "\tTime needed for calculating scores: 14.050472974777222\n",
      "Selecting classifiers..\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-7639739c9d73>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(positive_iis, negative_iis, num_classifiers, min_feature_width, max_feature_width, min_feature_height, max_feature_height)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# get best feature, i.e. with smallest error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mmin_error_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mbest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_error_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mbest_feature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_error_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Envs/CV-FBp3OsoO/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[0;32m-> 1222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/CV-FBp3OsoO/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifiers = learn(ii_pos_training,\n",
    "                    ii_neg_training,\n",
    "                    num_classifiers=num_classifiers,\n",
    "                    min_feature_height=min_feature_height,\n",
    "                    max_feature_height=max_feature_height,\n",
    "                    min_feature_width=min_feature_width,\n",
    "                    max_feature_width=max_feature_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results:\n",
      "Correctly identified Faces: 7/2429 (0.2882%)\n",
      "Correctly identified non-Faces: 57/8548 (0.6668%)\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 0/472 (0.0000%)\n",
      "Correctly identified non-Faces: 0/128 (0.0000%)\n"
     ]
    }
   ],
   "source": [
    "print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** Change the voting functions so that you can set a threshold for deciding a prediction.\n",
    "\n",
    "The threshold value indicates the minimum score for assigning a \"positive\" label (detect a face).\n",
    "\n",
    "Create the following functions\n",
    "\n",
    "- `ensemble_vote_t`: returns the final decision of a list of classifiers for a given threshold.\n",
    "- `ensemble_vote_all_t`: Iterates over a list of integral images and returns the  final decision of a list of classifiers for each of the images (for a given threshold).\n",
    "\n",
    "\n",
    "\n",
    "Using the list of 20 classifiers compute the following:\n",
    "\n",
    "- a) number of correct faces over all faces (in the train data)\n",
    "- b) number of correct non faces over all non faces (in the train data)\n",
    "- c) number of correct faces over all faces (in the test data)\n",
    "- d) number of correct non faces over all non faces (in the test data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The quantities have to be computed for each of the following thresholds:\n",
    "\n",
    "```\n",
    "thresholds = np.array([x for x in range(-5,5,1)])/10.\n",
    "```\n",
    "\n",
    "- Make a bar plot for a) b) c) and d). In the x axis write the threshold value. \n",
    "\n",
    "- Discuss what happens when you increase the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.array([x for x in range(-5,5,1)])/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_score(int_img, classifiers):\n",
    "    return sum([c.get_vote(int_img) for c in classifiers])\n",
    "\n",
    "def ensemble_vote_t(int_img, classifiers, t):\n",
    "    return int(ensemble_score(int_img, classifiers) > t)\n",
    "\n",
    "def ensemble_vote_all_t(int_imgs, classifiers, t=-0.1):\n",
    "    votes = []\n",
    "    for img in int_imgs:\n",
    "        votes.append(ensemble_vote_t(img, classifiers, t))\n",
    "    return votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_faces_train_t = []\n",
    "correct_non_faces_train_t = []\n",
    "correct_faces_test_t = []\n",
    "correct_non_faces_test_t = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    pos_training_results = ensemble_vote_all_t(ii_pos_training, classifiers, thresh)\n",
    "    neg_training_results = ensemble_vote_all_t(ii_neg_training, classifiers, thresh)\n",
    "    pos_testing_results = ensemble_vote_all_t(ii_pos_testing, classifiers, thresh)\n",
    "    neg_testing_results = ensemble_vote_all_t(ii_neg_testing, classifiers, thresh)\n",
    "    \n",
    "    correct_faces_train_t.append(sum(pos_training_results) / len(ii_pos_training))\n",
    "    correct_non_faces_train_t.append(sum(neg_training_results) / len(ii_neg_training))\n",
    "    correct_faces_test_t.append(sum(pos_testing_results) / len(ii_pos_training))\n",
    "    correct_non_faces_test_t.append(sum(neg_testing_results) / len(ii_neg_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.title('20-Classifiers Accuracy')\n",
    "\n",
    "plt.bar(thresholds - 0.030, correct_faces_train_t, width=0.02,\n",
    "        color='darkred', align='center', label='Train Faces')\n",
    "\n",
    "plt.bar(thresholds - 0.010, correct_non_faces_train_t, width=0.02,\n",
    "        color='orange', align='center', label='Train Non-Faces')\n",
    "\n",
    "plt.bar(thresholds + 0.010, correct_faces_test_t, width=0.02,\n",
    "        color='darkblue', align='center', label='Test Faces')\n",
    "\n",
    "plt.bar(thresholds + 0.030, correct_non_faces_test_t,\n",
    "        width=0.02, color='teal', align='center', label='Test Non-Faces')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mai-cv",
   "language": "python",
   "name": "mai-cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
